{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b070ca-f6ec-44a0-95eb-e42c97ae79ca",
   "metadata": {},
   "source": [
    "# Heart Attack - Kaggle competition V 5.0  \n",
    "### Author: Aniko Maraz, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033b497-52dd-444a-8821-c835df3b5359",
   "metadata": {},
   "source": [
    "<br> <br> Note: This is the 2nd version of the improved model, currently running in production: \n",
    "<br> <br>\n",
    "https://fake-heart-attack.streamlit.app/ <br> <br> \n",
    "This notebook includes an **XGBoost*** model with **probability estimation**. This version is optimised for __*precision*__ (not accuracy as required on Kaggle).\n",
    "\n",
    "I created this version because when predicting heart risk, not accuracy, but precision should be used, as the latter metric is a better indicator of how well the model picks up the positive cases. I also wanted to overcome the the possible shortcoming of the challenge, in which the best model (=highest accuracy) in Version 1 predicted all zeros (=low risk) on the ~1700 test cases, although in the train dataset there are ~35% positive cases. This indicates that the train and test datasets are possibly very different. The current version resulted in the prediction of 312 positive cases. \n",
    "<br> <br>\n",
    "Data exploration, feature engineering, etc. can be found in [a prettier version](https://github.com/anikomaraz/heart_attack_kaggle/blob/main/notebooks/heart_attack_v3_clean_KaggleV1.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccfec5-92ce-40e0-b74a-14209439c450",
   "metadata": {},
   "source": [
    "Further info and versions in my [Git Repo](https://github.com/anikomaraz/heart_attack_kaggle). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb85d8a-87c2-4de2-8e14-4bff35639d9f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e63f95-e903-463f-a3fb-3ae86b6d686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "import jupyter_black\n",
    "\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d6e06-ed92-49f7-bb5a-0908187f1852",
   "metadata": {},
   "source": [
    "## DATA: GET AND EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b421305-beea-45c5-b1f9-b3c94f485769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_train = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a33f4f-00ab-4649-9fe0-17281a66572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function to split blood pressure data (current format: 129/90)\n",
    "def split_blood_pressure(df):\n",
    "    df[[\"Systolic\", \"Diastolic\"]] = df[\"Blood Pressure\"].str.split(\"/\", expand=True)\n",
    "    df[\"Systolic\"] = pd.to_numeric(df[\"Systolic\"])\n",
    "    df[\"Diastolic\"] = pd.to_numeric(df[\"Diastolic\"])\n",
    "    df.drop(columns=[\"Blood Pressure\"], inplace=True)\n",
    "\n",
    "\n",
    "# split cholesterol according to sample mean\n",
    "cholesterol_sample_mean = df_raw_train[\"Cholesterol\"].mean()\n",
    "\n",
    "\n",
    "def split_cholesterol_sample(df):\n",
    "    df[\"Cholesterol_sample_split\"] = np.where(\n",
    "        df[\"Cholesterol\"] > cholesterol_sample_mean, 1, 0\n",
    "    )\n",
    "\n",
    "\n",
    "# create the new variables\n",
    "df = df_raw_train.copy()\n",
    "\n",
    "split_blood_pressure(df=df)\n",
    "split_cholesterol_sample(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2638a1-6bb5-4436-9bec-e5e452a1ab81",
   "metadata": {},
   "source": [
    "### Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4246cb37-c3b7-4816-9cd3-9a7cf280fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the features and the target\n",
    "X = df.drop(columns=\"Heart Attack Risk\")\n",
    "y = df[\"Heart Attack Risk\"]\n",
    "\n",
    "# Opt-in continuous and categorical variables\n",
    "continuous_vars = [\n",
    "    \"Age\",\n",
    "    \"Heart Rate\",\n",
    "    \"Exercise Hours Per Week\",\n",
    "    \"Stress Level\",\n",
    "    \"Sedentary Hours Per Day\",\n",
    "    \"Income\",\n",
    "    \"BMI\",\n",
    "    \"Triglycerides\",\n",
    "    \"Physical Activity Days Per Week\",\n",
    "    \"Sleep Hours Per Day\",\n",
    "    \"Systolic\",\n",
    "    \"Diastolic\",\n",
    "]\n",
    "\n",
    "categorical_vars = [\n",
    "    \"Diabetes\",\n",
    "    \"Family History\",\n",
    "    \"Obesity\",\n",
    "    \"Alcohol Consumption\",\n",
    "    \"Previous Heart Problems\",\n",
    "    \"Medication Use\",\n",
    "    \"Cholesterol_sample_split\",\n",
    "    \"Sex\",\n",
    "    \"Continent\",\n",
    "    \"Diet\",\n",
    "    \"Hemisphere\",\n",
    "]\n",
    "\n",
    "X_selected = X[continuous_vars + categorical_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c09af-f143-476d-b3f7-4ff2cf13dbdc",
   "metadata": {},
   "source": [
    "### Create preprocessing pipeline and train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c05f924-7052-4091-bd4f-e08245dbecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing steps for continuous and categorical features\n",
    "num_transformer = MinMaxScaler()\n",
    "cat_transformer = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "preproc_basic = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, continuous_vars),\n",
    "        (\"cat\", cat_transformer, categorical_vars),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Create pipelines for SVC\n",
    "xgb_pipe = make_pipeline(preproc_basic, XGBClassifier(random_state=6))\n",
    "\n",
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.3, random_state=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37016d96-f09e-4b7e-9e70-91c857da4d0b",
   "metadata": {},
   "source": [
    "## TRAIN AND TUNE THRESHOLD FOR PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "214dd5f1-13ad-4935-be25-dba9bfa5a67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5306122448979592 with precision score: 0.9994206257242179\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline\n",
    "xgb_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities for the training set\n",
    "train_probs = xgb_pipe.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate thresholds\n",
    "thresholds = np.linspace(0.4, 0.6, 50)\n",
    "best_threshold = None\n",
    "best_precision = 0.0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Convert probabilities to binary predictions based on the threshold\n",
    "    train_predictions = (train_probs > threshold).astype(int)\n",
    "\n",
    "    # Evaluate precision\n",
    "    precision = precision_score(y_train, train_predictions)\n",
    "\n",
    "    # Check if this threshold gives better precision\n",
    "    if precision > best_precision:\n",
    "        best_precision = precision\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Print the best threshold found\n",
    "print(f\"Best threshold: {best_threshold} with precision score: {best_precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7efa2-18ab-4d42-92e9-5a92d5e5dbfe",
   "metadata": {},
   "source": [
    "## Apply the best treshold to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bea534a1-683c-489c-8fbf-09ea1a78065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.3554987212276215\n",
      "Test accuracy: 0.5891583452211127\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for the test set\n",
    "test_probs = xgb_pipe.predict_proba(X_test)[:, 1]\n",
    "test_predictions = (test_probs > best_threshold).astype(int)\n",
    "\n",
    "# Evaluate precision on the test set with the tuned threshold\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f\"Test precision: {test_precision}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18408ef-e41e-4da4-90cc-7884f590b72c",
   "metadata": {},
   "source": [
    "## Preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ecd34e3-c201-4a0a-80c2-d0e3f35bf041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle_test = pd.read_csv(\"../data/test.csv\")  # read in test data provided by Kaggle\n",
    "\n",
    "# preprocess input data\n",
    "df_kaggle_test = df_kaggle_test.copy()\n",
    "\n",
    "split_blood_pressure(df=df_kaggle_test)\n",
    "split_cholesterol_sample(df=df_kaggle_test)\n",
    "\n",
    "X_df_kaggle_test_selected = df_kaggle_test[continuous_vars + categorical_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9910f-6dde-4035-a043-aa32857e7d1c",
   "metadata": {},
   "source": [
    "## Predict on Kaggle test set and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7fdd163-66d1-4a6f-9e85-401041ceba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the Kaggle test set\n",
    "kaggle_test_probs = xgb_pipe.predict_proba(X_df_kaggle_test_selected)[:, 1]\n",
    "\n",
    "# Apply the best threshold to Kaggle test set predictions\n",
    "kaggle_test_predictions = (kaggle_test_probs > best_threshold).astype(int)\n",
    "\n",
    "# Prepare submission dataframe\n",
    "df_kaggle_test = pd.read_csv(\"../data/test.csv\")\n",
    "df_kaggle_predicted_V5 = {\n",
    "    \"Patient ID\": df_kaggle_test[\"Patient ID\"],\n",
    "    \"Heart Attack Risk\": kaggle_test_predictions,\n",
    "}\n",
    "df_kaggle_predicted_V5_xgb_precision = pd.DataFrame(df_kaggle_predicted_V5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "644bc4db-7b9d-4756-b5d8-c4b0bee50d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission to CSV\n",
    "df_kaggle_predicted_V5_xgb_precision.to_csv(\n",
    "    \"../submission/df_kaggle_predicted_V5_xgb_precision.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49352182-417c-4b18-b650-f0ebe78afe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of cases in the unseen Kaggle test set\n",
    "len(df_kaggle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caf46c41-025e-4bc0-8787-8448bada624e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(kaggle_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc91192-83e3-4853-a7e2-c3b60324ceb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
